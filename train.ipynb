{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef8671c-ea26-4415-af8e-31042ea35a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.4 in /Users/azamat/anaconda3/lib/python3.11/site-packages (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e04fdb8-71e6-4d80-9eb8-4b2fd7aea857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import dgl.function as dglfn\n",
    "from collections import deque\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "from dataset import SepDataset, collate_fn\n",
    "from model import ModelNew\n",
    "import metrics\n",
    "\n",
    "seed = np.random.randint(2021, 2022) ##random\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e52e30-2873-4f1d-8012-e70dac2cd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    return now, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a538e919-ffc1-4760-8011-33d17697ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader_compound, criterion, optimizer,epoch,device):\n",
    "    model.train()\n",
    "    tbar = tqdm(train_loader_compound, total=len(train_loader_compound))\n",
    "    losses = []\n",
    "    t = time.time()\n",
    "    for i, data in enumerate(tbar):\n",
    "        data0 = [i.to(device) for i in data[0]]\n",
    "        ga, gr, gi, aff = data0\n",
    "        vina = data[1]\n",
    "        y_pred = model(ga,gr,gi,vina).squeeze()\n",
    "        y_true = aff.float().squeeze()\n",
    "\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        loss = criterion(y_pred,y_true).cuda()\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "#         tbar.set_description(f'epoch {epoch+1} loss {np.mean(losses[-10:]):.4f} grad {grad_norm:.4f}')\n",
    "\n",
    "    m_losses=np.mean(losses)\n",
    "\n",
    "    return m_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb42473d-66f6-48b3-b524-f3297af80ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_loader_compound, criterion,device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    tbar = tqdm(valid_loader_compound, total=len(valid_loader_compound))\n",
    "    for i, data in enumerate(tbar):\n",
    "        data0 = [i.to(device) for i in data[0]]\n",
    "        ga, gr, gi, aff = data0\n",
    "        vina = data[1]\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(ga,gr,gi,vina).squeeze()\n",
    "        y_true = aff.float().squeeze()\n",
    "        assert y_pred.shape == y_true.shape\n",
    "        loss = criterion(y_pred,y_true).cuda()\n",
    "        losses.append(loss.item())\n",
    "        outputs.append(y_pred.cpu().detach().numpy().reshape(-1))\n",
    "        targets.append(y_true.cpu().detach().numpy().reshape(-1))\n",
    "    targets = np.concatenate(targets).reshape(-1)\n",
    "    outputs = np.concatenate(outputs).reshape(-1)\n",
    "\n",
    "    evaluation = {\n",
    "        'c_index': metrics.c_index(targets, outputs),\n",
    "        'RMSE': metrics.RMSE(targets, outputs),\n",
    "        'MAE': metrics.MAE(targets, outputs),\n",
    "        'SD': metrics.SD(targets, outputs),\n",
    "        'CORR': metrics.CORR(targets, outputs),}\n",
    "    ml=np.mean(losses)\n",
    "\n",
    "    return ml, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c1efdaa-8231-4760-90cb-b69dc713fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    number_of_complexes = 423\n",
    "    \n",
    "    F=open(r'train_val_test_comp.pkl','rb')\n",
    "    content=pickle.load(F)\n",
    "    F.close()\n",
    "    vina_list= []\n",
    "    graphs = dgl.load_graphs('graphs_arr.bin')[0] # index 0 for graph, index 1 for labels, which we didn't put in the graph\n",
    "    labels = pd.read_csv('labels.csv')\n",
    "    vina_terms=open(r'Vina_terms.pkl','rb')\n",
    "    vina=pickle.load(vina_terms)\n",
    "    vina_terms.close()\n",
    "    # print(vina)\n",
    "    for i in range(number_of_complexes):\n",
    "        if labels.id[i] in vina.keys():\n",
    "            vina_list.append(vina[labels.id[i]])\n",
    "    # print(vina_list)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    compound_train = content[0]\n",
    "    compound_valid = content[1]\n",
    "    compound_test = content[2]\n",
    "    # print(compound_test)\n",
    "\n",
    "    train_dataset_compound = SepDataset([graphs[i] for i in compound_train], [vina_list[i] for i in compound_train], [labels.id[i] for i in compound_train], [labels.koff[i] for i in compound_train], ['a_conn','r_conn', 'int_l'])\n",
    "    valid_dataset_compound = SepDataset([graphs[i] for i in compound_valid], [vina_list[i] for i in compound_valid], [labels.id[i] for i in compound_valid], [labels.koff[i] for i in compound_valid], ['a_conn','r_conn', 'int_l'])\n",
    "    test_dataset_compound  = SepDataset([graphs[i] for i in compound_test],  [vina_list[i] for i in compound_test],  [labels.id[i] for i in compound_test],  [labels.koff[i] for i in compound_test],  ['a_conn','r_conn', 'int_l'])\n",
    "        \n",
    "    train_loader_compound = DataLoader(train_dataset_compound, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn,pin_memory=False,drop_last=False,)\n",
    "    valid_loader_compound = DataLoader(valid_dataset_compound, batch_size=8, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "    test_loader_compound = DataLoader(test_dataset_compound, batch_size=8, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "    print(train_loader_compound)\n",
    "\n",
    "    model = ModelNew()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), 1.2e-4, weight_decay=1e-6)   ### (model.parameters(), 1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=40, eta_min=1e-6)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    n_epoch = 80\n",
    "    best_R = 0.0\n",
    "    for epoch in range(n_epoch):\n",
    "        ll = train(model, train_loader_compound, criterion, optimizer,epoch,device)\n",
    "        if epoch%1==0:\n",
    "            l,evaluation = valid(model, valid_loader_compound, criterion,device)\n",
    "            l_, evaluation_ = valid(model, test_loader_compound, criterion,device)\n",
    "            print(f'epoch {epoch+1} train_loss {ll:.5f} valid_loss {l:.5f}')\n",
    "            clear_output()\n",
    "            if evaluation_['CORR']>best_R:\n",
    "                best_R= evaluation_['CORR']\n",
    "                torch.save({'model': model.state_dict()}, '../model/model.pth')\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52e21f1e-6529-4564-b9a9-c7d4d10f404f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: dgl\n",
      "Version: 1.1.2.post1\n",
      "Summary: Deep Graph Library\n",
      "Home-page: https://github.com/dmlc/dgl\n",
      "Author: \n",
      "Author-email: \n",
      "License: APACHE\n",
      "Location: /Users/azamat/anaconda3/lib/python3.11/site-packages\n",
      "Requires: networkx, numpy, psutil, requests, scipy, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a31118e-c4dd-4422-8289-2fe86bf9d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1808cff10>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8a2e8993b940b4af74051b99eaab4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DGLError",
     "evalue": "[22:31:16] /tmp/dgl_src/src/runtime/c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) 1   libdgl.dylib                        0x000000016f747aef dmlc::LogMessageFatal::~LogMessageFatal() + 111\n  [bt] (1) 2   libdgl.dylib                        0x000000016fb381a3 dgl::runtime::DeviceAPIManager::GetAPI(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, bool) + 371\n  [bt] (2) 3   libdgl.dylib                        0x000000016fb37f81 dgl::runtime::DeviceAPIManager::GetAPI(int, bool) + 353\n  [bt] (3) 4   libdgl.dylib                        0x000000016fb49fe3 dgl::runtime::NDArray::Empty(std::__1::vector<long long, std::__1::allocator<long long>>, DGLDataType, DGLContext) + 403\n  [bt] (4) 5   libdgl.dylib                        0x000000016f70e02d dgl::runtime::NDArray::CopyTo(DGLContext const&) const + 253\n  [bt] (5) 6   libdgl.dylib                        0x000000016fcdbed3 dgl::aten::COOMatrix::CopyTo(DGLContext const&) const + 179\n  [bt] (6) 7   libdgl.dylib                        0x000000016fcc61ad dgl::UnitGraph::COO::CopyTo(DGLContext const&) const + 253\n  [bt] (7) 8   libdgl.dylib                        0x000000016fcc5931 dgl::UnitGraph::CopyTo(std::__1::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&) + 497\n  [bt] (8) 9   libdgl.dylib                        0x000000016fb9b02b dgl::HeteroGraph::CopyTo(std::__1::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&) + 379\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[69], line 44\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m best_R \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epoch):\n\u001b[0;32m---> 44\u001b[0m     ll \u001b[38;5;241m=\u001b[39m train(model, train_loader_compound, criterion, optimizer,epoch,device)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     46\u001b[0m         l,evaluation \u001b[38;5;241m=\u001b[39m valid(model, valid_loader_compound, criterion,device)\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader_compound, criterion, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m ga, gr, gi, aff \u001b[38;5;241m=\u001b[39m data0\n\u001b[1;32m      9\u001b[0m vina \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(ga,gr,gi,vina)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     11\u001b[0m y_true \u001b[38;5;241m=\u001b[39m aff\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m y_true\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/UC/STDM/project/project_code/model.py:47\u001b[0m, in \u001b[0;36mModelNew.forward\u001b[0;34m(self, ga, gr, gi, vina)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ga, gr, gi, vina): \n\u001b[1;32m     46\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     ga \u001b[38;5;241m=\u001b[39m ga\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m     gr \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m     gi \u001b[38;5;241m=\u001b[39m gi\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dgl/heterograph.py:5709\u001b[0m, in \u001b[0;36mDGLGraph.to\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m   5706\u001b[0m ret \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5708\u001b[0m \u001b[38;5;66;03m# 1. Copy graph structure\u001b[39;00m\n\u001b[0;32m-> 5709\u001b[0m ret\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mcopy_to(utils\u001b[38;5;241m.\u001b[39mto_dgl_context(device))\n\u001b[1;32m   5711\u001b[0m \u001b[38;5;66;03m# 2. Copy features\u001b[39;00m\n\u001b[1;32m   5712\u001b[0m \u001b[38;5;66;03m# TODO(minjie): handle initializer\u001b[39;00m\n\u001b[1;32m   5713\u001b[0m new_nframes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dgl/heterograph_index.py:255\u001b[0m, in \u001b[0;36mHeteroGraphIndex.copy_to\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy_to\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[1;32m    241\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Copy this immutable graph index to the given device context.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m    NOTE: this method only works for immutable graph index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m        The graph index on the given device context.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CAPI_DGLHeteroCopyTo(\u001b[38;5;28mself\u001b[39m, ctx\u001b[38;5;241m.\u001b[39mdevice_type, ctx\u001b[38;5;241m.\u001b[39mdevice_id)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dgl/_ffi/_ctypes/function.py:212\u001b[0m, in \u001b[0;36mFunctionBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    210\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m DGLValue()\n\u001b[1;32m    211\u001b[0m ret_tcode \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int()\n\u001b[0;32m--> 212\u001b[0m check_call(\n\u001b[1;32m    213\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mDGLFuncCall(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    215\u001b[0m         values,\n\u001b[1;32m    216\u001b[0m         tcodes,\n\u001b[1;32m    217\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mc_int(num_args),\n\u001b[1;32m    218\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(ret_val),\n\u001b[1;32m    219\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(ret_tcode),\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    221\u001b[0m )\n\u001b[1;32m    222\u001b[0m _ \u001b[38;5;241m=\u001b[39m temp_args\n\u001b[1;32m    223\u001b[0m _ \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/dgl/_ffi/base.py:70\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(py_str(_LIB\u001b[38;5;241m.\u001b[39mDGLGetLastError()))\n",
      "\u001b[0;31mDGLError\u001b[0m: [22:31:16] /tmp/dgl_src/src/runtime/c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) 1   libdgl.dylib                        0x000000016f747aef dmlc::LogMessageFatal::~LogMessageFatal() + 111\n  [bt] (1) 2   libdgl.dylib                        0x000000016fb381a3 dgl::runtime::DeviceAPIManager::GetAPI(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>>, bool) + 371\n  [bt] (2) 3   libdgl.dylib                        0x000000016fb37f81 dgl::runtime::DeviceAPIManager::GetAPI(int, bool) + 353\n  [bt] (3) 4   libdgl.dylib                        0x000000016fb49fe3 dgl::runtime::NDArray::Empty(std::__1::vector<long long, std::__1::allocator<long long>>, DGLDataType, DGLContext) + 403\n  [bt] (4) 5   libdgl.dylib                        0x000000016f70e02d dgl::runtime::NDArray::CopyTo(DGLContext const&) const + 253\n  [bt] (5) 6   libdgl.dylib                        0x000000016fcdbed3 dgl::aten::COOMatrix::CopyTo(DGLContext const&) const + 179\n  [bt] (6) 7   libdgl.dylib                        0x000000016fcc61ad dgl::UnitGraph::COO::CopyTo(DGLContext const&) const + 253\n  [bt] (7) 8   libdgl.dylib                        0x000000016fcc5931 dgl::UnitGraph::CopyTo(std::__1::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&) + 497\n  [bt] (8) 9   libdgl.dylib                        0x000000016fb9b02b dgl::HeteroGraph::CopyTo(std::__1::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&) + 379\n\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd122bd-6e0a-4431-a4a1-74925f2bd530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemenv",
   "language": "python",
   "name": "chemenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
